{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NOEEHzZQAQQO"},"outputs":[],"source":["import re\n","import unicodedata\n","import urllib3\n","import zipfile\n","import shutil\n","import numpy as np\n","from tensorflow import keras\n","import tensorflow as tf\n","from tensorflow.keras.layers import Embedding, GRU, Dense\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import layers\n","import pandas as pd\n","import collections\n","import logging\n","import os\n","import pathlib\n","import strings\n","import sys\n","import time\n","import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","import pickle\n","import urllib.request\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"atlCKYzWWlEM"},"outputs":[],"source":["# with open('./sents_kor_in_hannanum_transformer.pkl', 'rb') as f:\n","#   sents_kor_in=pickle.load(f)\n","# with open('./sents_en_in_hannanum_transformer.pkl', 'rb') as f:\n","#   sents_en_in=pickle.load(f)\n","\n","with open('./sents_kor_transformer.pkl', 'rb') as f:\n","  sents_kor_in=pickle.load(f)\n","with open('./sents_en_transformer.pkl', 'rb') as f:\n","  sents_en_in=pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8NPwLNHcwdX"},"outputs":[],"source":["# 서브워드텍스트인코더를 사용하여 질문과 답변을 모두 포함한 단어 집합(Vocabulary) 생성\n","tokenizer_kor = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    sents_kor_in, target_vocab_size=2**13)\n","tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    sents_en_in, target_vocab_size=2**13)\n","\n","# 시작 토큰과 종료 토큰에 대한 정수 부여.\n","KOR_START_TOKEN, KOR_END_TOKEN = [tokenizer_kor.vocab_size], [tokenizer_kor.vocab_size + 1]\n","EN_START_TOKEN, EN_END_TOKEN = [tokenizer_en.vocab_size], [tokenizer_en.vocab_size + 1]\n","\n","# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n","KOR_VOCAB_SIZE = tokenizer_kor.vocab_size+2\n","EN_VOCAB_SIZE = tokenizer_en.vocab_size + 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XBrFjrebcwdY"},"outputs":[],"source":["MAX_LENGTH = 50\n","\n","# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n","def tokenize_and_filter(inputs, outputs):\n","  tokenized_inputs, tokenized_outputs = [], []\n","  \n","  for (sentence1, sentence2) in zip(inputs, outputs):\n","    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n","    # sentence1 = KOR_START_TOKEN+ tokenizer_kor.encode(sentence1)+ KOR_END_TOKEN\n","    sentence1 = KOR_START_TOKEN + tokenizer_kor.encode(sentence1)+ KOR_END_TOKEN\n","    sentence2 = EN_START_TOKEN + tokenizer_en.encode(sentence2) + EN_END_TOKEN\n"," \n","    tokenized_inputs.append(sentence1)\n","    tokenized_outputs.append(sentence2)\n","  \n","  # 패딩\n","  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n","  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n","  \n","  return tokenized_inputs, tokenized_outputs\n","\n","questions, answers = tokenize_and_filter(sents_kor_in, sents_en_in)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSD0T_VOcwdY","outputId":"339a14f1-e834-44d6-bdb2-44fd23bf399d"},"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합의 크기(Vocab size): 8203\n","단어 집합의 크기(Vocab size): 8256\n","전체 샘플의 수(Number of samples): 200000\n"]}],"source":["print('단어 집합의 크기(Vocab size): {}'.format(KOR_VOCAB_SIZE))\n","print('단어 집합의 크기(Vocab size): {}'.format(EN_VOCAB_SIZE))\n","print('전체 샘플의 수(Number of samples): {}'.format(len(questions)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vo7a-mMkcwdZ"},"outputs":[],"source":["# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n","# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 20000\n","\n","# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n","dataset = tf.data.Dataset.from_tensor_slices((\n","    {\n","        'inputs': questions,\n","        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n","    },\n","    {\n","        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n","    },\n","))\n","\n","dataset = dataset.cache()\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDkQ22FycwdZ"},"outputs":[],"source":["# 최종 버전\n","class PositionalEncoding(tf.keras.layers.Layer):\n","  def __init__(self, position, d_model):\n","    super(PositionalEncoding, self).__init__()\n","    self.pos_encoding = self.positional_encoding(position, d_model)\n","\n","  def get_angles(self, position, i, d_model):\n","    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","    return position * angles\n","\n","  def positional_encoding(self, position, d_model):\n","    angle_rads = self.get_angles(\n","        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n","        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :], # 0 ~ d_model\n","        d_model=d_model)\n","\n","    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n","    sines = tf.math.sin(angle_rads[:, 0::2])\n","\n","    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n","    cosines = tf.math.cos(angle_rads[:, 1::2])\n","\n","    angle_rads = np.zeros(angle_rads.shape)\n","    angle_rads[:, 0::2] = sines\n","    angle_rads[:, 1::2] = cosines\n","    \n","    pos_encoding = tf.constant(angle_rads)\n","    print(pos_encoding.shape)\n","    pos_encoding = pos_encoding[tf.newaxis, ...]\n","    print(pos_encoding.shape)\n","    return tf.cast(pos_encoding, tf.float32)\n","\n","  def call(self, inputs):\n","    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srtdu4VEcwda"},"outputs":[],"source":["def scaled_dot_product_attention(query, key, value, mask):\n","  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n","  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n","  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n","\n","  # Q와 K의 곱. 어텐션 스코어 행렬.\n","  matmul_qk = tf.matmul(query, key, transpose_b=True)\n","\n","  # 스케일링\n","  # dk의 루트값으로 나눠준다.\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","  logits = matmul_qk / tf.math.sqrt(depth)\n","\n","  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n","  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n","  if mask is not None:\n","    logits += (mask * -1e9)\n","\n","  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n","  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n","  attention_weights = tf.nn.softmax(logits, axis=-1)\n","\n","  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","  output = tf.matmul(attention_weights, value)\n","\n","  return output, attention_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ry-5OT1Ocwdb"},"outputs":[],"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","    super(MultiHeadAttention, self).__init__(name=name)\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0\n","\n","    # d_model을 num_heads로 나눈 값.\n","    # 논문 기준 : 64\n","    self.depth = d_model // self.num_heads\n","\n","    # WQ, WK, WV에 해당하는 밀집층 정의\n","    self.query_dense = tf.keras.layers.Dense(units=d_model)\n","    self.key_dense = tf.keras.layers.Dense(units=d_model)\n","    self.value_dense = tf.keras.layers.Dense(units=d_model)\n","\n","    # WO에 해당하는 밀집층 정의\n","    self.dense = tf.keras.layers.Dense(units=d_model)\n","\n","  # num_heads 개수만큼 q, k, v를 split하는 함수\n","  def split_heads(self, inputs, batch_size):\n","    inputs = tf.reshape(\n","        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n","    \n","    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n","\n","  def call(self, inputs):\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n","        'value'], inputs['mask']\n","    batch_size = tf.shape(query)[0]\n","\n","    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n","    # q : (batch_size, query의 문장 길이, d_model)\n","    # k : (batch_size, key의 문장 길이, d_model)\n","    # v : (batch_size, value의 문장 길이, d_model)\n","    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n","    query = self.query_dense(query)\n","    key = self.key_dense(key)\n","    value = self.value_dense(value)\n","\n","    # 2. 헤드 나누기\n","    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n","    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","\n","    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n","    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n","    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    # 4. 헤드 연결(concatenate)하기\n","    # (batch_size, query의 문장 길이, d_model)\n","    concat_attention = tf.reshape(scaled_attention,\n","                                  (batch_size, -1, self.d_model))\n","\n","    # 5. WO에 해당하는 밀집층 지나기\n","    # (batch_size, query의 문장 길이, d_model)\n","    outputs = self.dense(concat_attention)\n","\n","    return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pd1nPydUcwdc"},"outputs":[],"source":["def create_padding_mask(x):\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","  # (batch_size, 1, 1, key의 문장 길이)\n","  return mask[:, tf.newaxis, tf.newaxis, :]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6JScHFLEcwdc"},"outputs":[],"source":["def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","\n","  # 인코더는 패딩 마스크 사용 -> 어텐션에서 패딩 토큰 제외\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n","  attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n","          'mask': padding_mask # 패딩 마스크 사용\n","      })\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","  attention = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(inputs + attention)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n","  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention + outputs)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SLiPpP9lcwdd"},"outputs":[],"source":["def encoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name=\"encoder\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 포지셔널 인코딩 + 드롭아웃\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  # 인코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n","    )([outputs, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7IsDPrHjcwdd"},"outputs":[],"source":["# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n","def create_look_ahead_mask(x):\n","  seq_len = tf.shape(x)[1]\n","  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0) #  Lower triangular part.\n","  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n","  return tf.maximum(look_ahead_mask, padding_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PEM4s8xcwdd"},"outputs":[],"source":["def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","\n","  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name=\"look_ahead_mask\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n","  attention1 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_1\")(inputs={\n","          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n","          'mask': look_ahead_mask # 룩어헤드 마스크\n","      })\n","\n","  # 잔차 연결과 층 정규화\n","  attention1 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention1 + inputs)\n","\n","  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n","  attention2 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_2\")(inputs={\n","          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n","          'mask': padding_mask # 패딩 마스크\n","      })\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n","  attention2 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention2 + attention1)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n","  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(outputs + attention2)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v0Y2OPM1cwde"},"outputs":[],"source":["def decoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name='decoder'):\n","  inputs = tf.keras.Input(shape=(None,), name='inputs')\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n","\n","  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name='look_ahead_mask')\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 포지셔널 인코딩 + 드롭아웃\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  # 디코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name='decoder_layer_{}'.format(i),\n","    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jjQbF6LDcwde"},"outputs":[],"source":["def loss_function(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","\n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","      from_logits=True, reduction='none')(y_true, y_pred)\n","\n","  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32) # y_true가 0(패딩이면) -> 0 , 1이면 -> 1\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.reduce_mean(loss) #Computes the mean of elements across dimensions of a tensor.\n","\n","# loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","#     from_logits=True, reduction='none')\n","\n","# def loss_function(real, pred):\n","#   mask = tf.math.logical_not(tf.math.equal(real, 0))\n","#   loss_ = loss_object(real, pred)\n","\n","#   mask = tf.cast(mask, dtype=loss_.dtype)\n","#   loss_ *= mask\n","\n","#   return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlLER0YFcwde"},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps**-1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"ZTLNTAzIcwdf","outputId":"a5a919f5-d694-4f56-8858-012e9e0ac815"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, 'Train Step')"]},"metadata":{},"execution_count":18},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["sample_learning_rate = CustomSchedule(d_model=516)\n","\n","plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n","plt.ylabel(\"Learning Rate\")\n","plt.xlabel(\"Train Step\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qb275vbIcwdf"},"outputs":[],"source":["# tf.keras.backend.clear_session()\n","\n","# # Hyper-parameters\n","# NUM_LAYERS = 2\n","# D_MODEL = 256\n","# NUM_HEADS = 8\n","# DFF = 512\n","# DROPOUT = 0.1\n","\n","# model = Transformer(\n","#     vocab_size=KOR_VOCAB_SIZE,\n","#     num_layers=NUM_LAYERS,\n","#     dff=DFF,\n","#     d_model=D_MODEL,\n","#     num_heads=NUM_HEADS,\n","#     dropout=DROPOUT)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vyatTYEvcwdf"},"outputs":[],"source":["def Transformer(vocab_size_kor,vocab_size_en, num_layers, dff,\n","                d_model, num_heads, dropout,\n","                name=\"transformer\"):\n","\n","  # 인코더의 입력\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","\n","  # 디코더의 입력\n","  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n","\n","  # 인코더의 패딩 마스크\n","  enc_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='enc_padding_mask')(inputs)\n","\n","  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n","  look_ahead_mask = tf.keras.layers.Lambda(\n","      create_look_ahead_mask, output_shape=(1, None, None),\n","      name='look_ahead_mask')(dec_inputs)\n","\n","  # 디코더의 패딩 마스크(두번째 서브층)\n","  dec_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='dec_padding_mask')(inputs)\n","\n","##################################################################\n","\n","  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n","  enc_outputs = encoder(vocab_size=vocab_size_kor, num_layers=num_layers, dff=dff,\n","      d_model=d_model, num_heads=num_heads, dropout=dropout,\n","  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n","\n","  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n","  dec_outputs = decoder(vocab_size=vocab_size_en, num_layers=num_layers, dff=dff,\n","      d_model=d_model, num_heads=num_heads, dropout=dropout,\n","  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n","\n","  # 다음 단어 예측을 위한 출력층\n","  outputs = tf.keras.layers.Dense(units=vocab_size_en, name=\"outputs\")(dec_outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1B4U_Msecwdf","outputId":"e1dc96a8-ebd6-4323-d24d-f3211a84aed7"},"outputs":[{"output_type":"stream","name":"stdout","text":["(8203, 512)\n","(1, 8203, 512)\n","(8256, 512)\n","(1, 8256, 512)\n"]}],"source":["tf.keras.backend.clear_session()\n","\n","# Hyper-parameters\n","NUM_LAYERS = 2\n","D_MODEL = 512\n","NUM_HEADS = 8\n","DFF = 512\n","# DROPOUT = tf.constant(0.1,dtype=tf.float32)\n","DROPOUT = 0.1\n","\n","model = Transformer(\n","    vocab_size_kor=KOR_VOCAB_SIZE,\n","    vocab_size_en=EN_VOCAB_SIZE,\n","    num_layers=NUM_LAYERS,\n","    dff=DFF,\n","    d_model=D_MODEL,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BBqaUTaYcwdg"},"outputs":[],"source":["MAX_LENGTH = 50\n","\n","learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","def accuracy(y_true, y_pred):\n","  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rUNTgdhcwdg","outputId":"a4e59821-399e-478d-b56a-d2107ffa6a08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","3125/3125 [==============================] - 387s 124ms/step - loss: 0.9210 - accuracy: 0.1418\n","Epoch 2/5\n","3125/3125 [==============================] - 386s 124ms/step - loss: 0.7668 - accuracy: 0.1585\n","Epoch 3/5\n","3125/3125 [==============================] - 385s 123ms/step - loss: 0.6821 - accuracy: 0.1691\n","Epoch 4/5\n","3125/3125 [==============================] - 385s 123ms/step - loss: 0.6235 - accuracy: 0.1771\n","Epoch 5/5\n","3125/3125 [==============================] - 386s 123ms/step - loss: 0.5789 - accuracy: 0.1834\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2ef076dd90>"]},"metadata":{},"execution_count":38}],"source":["EPOCHS = 5\n","# with tf.device('/GPU:0'):\n","model.fit(dataset, epochs=EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GlP4XUsgcwdg"},"outputs":[],"source":["def preprocess_sentence(sentence):\n","  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","  sentence = sentence.strip()\n","  return sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gIi1vzWbcwdh"},"outputs":[],"source":["def evaluate(sentence):\n","  sentence = preprocess_sentence(sentence)\n","\n","  # sentence = tf.expand_dims(\n","  #     START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n","  sentence = tf.expand_dims(\n","      KOR_START_TOKEN + tokenizer_kor.encode(sentence) + KOR_END_TOKEN, axis=0)\n","  output = tf.expand_dims(EN_START_TOKEN, 0)\n","\n","  # 디코더의 예측 시작\n","  for i in range(MAX_LENGTH):\n","    predictions = model(inputs=[sentence, output], training=False)\n","\n","    # 현재(마지막) 시점의 예측 단어를 받아온다.\n","    predictions = predictions[:, -1:, :]\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n","    if tf.equal(predicted_id, EN_END_TOKEN[0]):\n","      break\n","\n","    # 마지막 시점의 예측 단어를 출력에 연결한다.\n","    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output, axis=0)\n","\n","\n","def predict(sentence):\n","  prediction = evaluate(sentence)\n","\n","  predicted_sentence = tokenizer_en.decode(\n","      [i for i in prediction if i < EN_VOCAB_SIZE and not i==EN_END_TOKEN[0] and not i==EN_START_TOKEN[0]])\n","\n","  print('Input: {}'.format(sentence))\n","  print('Output: {}'.format(predicted_sentence))\n","\n","  return predicted_sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FfDXafmKcwdh","outputId":"6fa79a21-6f81-4db4-ab5c-2ad8567f5bd1"},"outputs":[{"ename":"ValueError","evalue":"Received id 8254 which is invalid. Ids must be within [0, 8254).","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\VS_Code_Repository\\DeepLearning_Alpaco\\음성인식\\k2e_NMT_Transformer_v6_2.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/VS_Code_Repository/DeepLearning_Alpaco/%EC%9D%8C%EC%84%B1%EC%9D%B8%EC%8B%9D/k2e_NMT_Transformer_v6_2.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(tokenizer_en\u001b[39m.\u001b[39;49mdecode(EN_START_TOKEN))\n","File \u001b[1;32mc:\\Users\\vzb88\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_datasets\\core\\deprecated\\text\\subword_text_encoder.py:108\u001b[0m, in \u001b[0;36mSubwordTextEncoder.decode\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[39mreturn\u001b[39;00m []\n\u001b[0;32m    107\u001b[0m \u001b[39mfor\u001b[39;00m subword_id \u001b[39min\u001b[39;00m subword_ids:\n\u001b[1;32m--> 108\u001b[0m   subword \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_id_to_subword(subword_id)\n\u001b[0;32m    109\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(subword, six\u001b[39m.\u001b[39mbinary_type):\n\u001b[0;32m    110\u001b[0m     \u001b[39m# Byte-encoded\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     prev_bytes\u001b[39m.\u001b[39mappend(subword)\n","File \u001b[1;32mc:\\Users\\vzb88\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_datasets\\core\\deprecated\\text\\subword_text_encoder.py:173\u001b[0m, in \u001b[0;36mSubwordTextEncoder._id_to_subword\u001b[1;34m(self, subword_id)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39m\"\"\"Converts a subword integer ID to a subword string.\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m subword_id \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m subword_id \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_size \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mReceived id \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m which is invalid. Ids must be within \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m[0, \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (subword_id \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_size))\n\u001b[0;32m    176\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m subword_id \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_subwords):\n\u001b[0;32m    177\u001b[0m   \u001b[39m# Subword\u001b[39;00m\n\u001b[0;32m    178\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_subwords[subword_id]\n","\u001b[1;31mValueError\u001b[0m: Received id 8254 which is invalid. Ids must be within [0, 8254)."]}],"source":["print(tokenizer_en.decode(EN_START_TOKEN))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiIZlW2Kcwdi","outputId":"5d82ca57-ae5e-46ce-c8dc-24fe807ce259"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n"]},{"ename":"UnicodeDecodeError","evalue":"'utf-8' codec can't decode byte 0xb5 in position 237: invalid start byte","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[1;32mc:\\VS_Code_Repository\\DeepLearning_Alpaco\\음성인식\\k2e_NMT_Transformer_v6_2.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/VS_Code_Repository/DeepLearning_Alpaco/%EC%9D%8C%EC%84%B1%EC%9D%B8%EC%8B%9D/k2e_NMT_Transformer_v6_2.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/GPU:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/VS_Code_Repository/DeepLearning_Alpaco/%EC%9D%8C%EC%84%B1%EC%9D%B8%EC%8B%9D/k2e_NMT_Transformer_v6_2.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39;49m\u001b[39mk2eTransformer.ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n","File \u001b[1;32mc:\\Users\\vzb88\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\vzb88\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb5 in position 237: invalid start byte"]}],"source":["with tf.device('/GPU:0'):\n","    model.save('k2eTransformer.ckpt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWDxXG_Rcwdi","outputId":"10210839-2f4d-41f0-f2f5-9698a732abde"},"outputs":[{"output_type":"stream","name":"stdout","text":["Bible Coloring' is a coloring application that allows you to experience beautiful stories in the Bible .\n","[4141, 469, 4911, 1297, 361, 254, 8, 6, 1189, 44, 1354, 15, 4819, 7, 4, 414, 416, 3669, 11, 2, 4141, 557, 1]\n","Bible Coloring' is a coloring application that allows you to experience beautiful stories in the Bible .\n"]}],"source":["print(sents_en_in[0])\n","encoded=tokenizer_en.encode(sents_en_in[0])\n","print(encoded)\n","print(tokenizer_en.decode(encoded))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Og7XWeZEcwdi","outputId":"5933f294-711f-42ae-aace-41cf001488f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 영화 볼래?\n","Output: Would you like to see a movie ?\n"]}],"source":["output = predict('영화 볼래?')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WF3iRo0cwdj","outputId":"a44fecc7-e457-4e77-df3e-a47d56308335"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 내가 만든 파스타 먹어 볼래?\n","Output: Would you like to try pasta I made ?\n","Would you like to try pasta I made ?\n"]}],"source":["output = predict('내가 만든 파스타 먹어 볼래?')\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rtLl2Docwdj","outputId":"767c7b3f-0cf3-4f9a-ed30-df0842232be4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 추석때 만나서 한잔 할 사람?\n","Output: Do you have a drink when you spend Chuseok ?\n"]}],"source":["output = predict('추석때 만나서 한잔 할 사람?')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9NA8NYJ5cwdj","outputId":"384b76f3-f513-4337-dd13-8aa794e1c0a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 양파즙 개좋아\n","Output: I like onions and running .\n"]}],"source":["output = predict('양파즙 개좋아')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fsRIUyX8cwdj","outputId":"3756e63a-c3e6-465d-ca3b-7b3eab9fa3cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 저는 오늘 할일이 많아서\n","Output: I have a lot of work to do .\n"]}],"source":["output = predict('저는 오늘 할일이 많아서')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6ig7e8Ocwdj","outputId":"23dd9741-9b92-406f-944d-fbfde19a8e4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=19Dl6inqAsmKz_JKWhIufL4OTm2j6D9uV\n","To: /content/k2e_target.csv\n","100% 7.25k/7.25k [00:00<00:00, 10.4MB/s]\n"]}],"source":["!gdown --id 19Dl6inqAsmKz_JKWhIufL4OTm2j6D9uV"]},{"cell_type":"code","source":["df = pd.read_csv('k2e_target.csv')"],"metadata":{"id":"qInD82Hoi1Yc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dic={\n","    '한글':df['한글'],\n","    'English':[]\n","}\n","for i in df['한글']:\n","  dic['English'].append(predict(i))\n","\n","df_dic= pd.dataframe(dic)\n","df_dic.to_csv('번역결과3.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_xviTQ5jB-H","outputId":"9e81b88d-e26c-4da4-a2eb-c530e2b8db76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 정리가 필요하겠네요.\n","Output: I need to keep up with my seat .\n","Input: 처음 만났을 때를 떠올려 보세요\n","Output: Please leave when you first met .\n","Input: 구썸남 인스타에 좋아요 누름.\n","Output: It's good to be in Gukan .\n","Input: 있었던 일을 차분히 생각해봐요.\n","Output: Let's think about what happened in the future .\n","Input: 많이 찍다보면 조금씩 실력이 늘거예요.\n","Output: I will improve little by little by little by little when I take a picture .\n","Input: 가능하면 참석하는 게 좋겠죠.\n","Output: I hope we can participate if possible .\n","Input: 비밀연애가 말도 못하고 힘들죠.\n","Output: It's hard to talk without a secret .\n","Input: 자신을 너무 비난하지 마세요.\n","Output: Don't be too critical .\n","Input: 한가지만 보면 몰라요.\n","Output: I don't know if I look at it .\n","Input: 당신이 덜 다치는 쪽으로 하세요.\n","Output: Please take the way you are not going to work .\n","Input: 전 다른 일을 많이 벌려요. 정신없이 바쁘면 잊혀지더라고요.\n","Output: I forgot to make other tasks without any physical strength .\n","Input: 나중에 후회할 거예요.\n","Output: I will regret later .\n","Input: 장마인데 건조기 사는게 좋을까\n","Output: It's a dry end of the dry sauna .\n","Input: 뜻대로 되는게 많지 않죠.\n","Output: There are not many things you will do as you wish .\n","Input: 울어도 돼요.\n","Output: You can cry easily .\n","Input: 환승 가능?\n","Output: Can I transfer the transfer ?\n","Input: 여유를 가지세요.\n","Output: Please take a rest .\n","Input: 저는 힘들다고 생각해요.\n","Output: I think it's hard to me .\n","Input: 안녕하세요.\n","Output: Hello ,  I'm happy to be here .\n","Input: 뭐 입고 나가지?\n","Output: What are you wearing and out ?\n","Input: 나들이 가보세요.\n","Output: Go to see them .\n","Input: 결혼하면 안 좋은 점?\n","Output: Is it good when you get married ?\n","Input: 헤아릴 수 없는 것.\n","Output: I can't live in .\n","Input: 사람이 크죠.\n","Output: The person is huge .\n","Input: 이제 은퇴해야 하나?\n","Output: Is it one of the retirement ?\n","Input: 심경의 변화가 있었나봅니다.\n","Output: There was a change in the mind .\n","Input: 나 보고 잘 웃는 여자애 나 좋아하는 건가?\n","Output: Do you like a girl or a girl who smiles well ?\n","Input: 시간이 더 많이 지나가길 바랄게요.\n","Output: I hope you pass more .\n","Input: 새로 적응해야겠네요.\n","Output: I think I should adapt to the new environment .\n","Input: 아무 것도 안해도 괜찮아요.\n","Output: Any is fine without any reason .\n","Input: 좋아하는거 어떤 느낌이야?\n","Output: What kind of feeling is the feeling you like ?\n","Input: 사랑 참 별거없네.\n","Output: There is no love with love .\n","Input: 괜찮은 줄 알았다.\n","Output: I thought it was fine .\n","Input: 제가 드리고 싶네요.\n","Output: I want to give you .\n","Input: 좋아하는 사람 포기하는 방법 있어?\n","Output: Is there any way to give up people ?\n","Input: 철밥통 되기가 어디 쉽겠어요.\n","Output: It will be easy where you can eat .\n","Input: 당신.\n","Output: You are free .\n","Input: 표현하지 않고 끝낸다면 후회할 수 있어요.\n","Output: I can regret if you don't express it and end it to me .\n","Input: 밀당을 하고 싶으시군요.\n","Output: You must have a close room .\n","Input: 비와 당신.\n","Output: You and me .\n","Input: 오늘 택배기사님들 쉬는 날이예요.\n","Output: Today is the day of the delivery engineer .\n","Input: 미인은 잠꾸러기라던데요.\n","Output: Mitsui is a little na .\n","Input: 생리현상은 늦게 트는 게 좋죠.\n","Output: The ecosystem is good for us to get back late .\n","Input: 일찍 퇴근하고 쉬고 있어\n","Output: I'm taking a rest after work .\n","Input: 회사와 자신에 대해서 더 공부해서 자신감을 가져보세요.\n","Output: Study more and take your own confidence .\n","Input: 확신이 있을 때 시작해보세요.\n","Output: Start up when you are convinced .\n","Input: 사랑한다고 표현해달라고 말해보세요.\n","Output: Tell me to say you love and expressed .\n","Input: 밤새 많은 생각을 했나봐요.\n","Output: I think I had a lot of thinking about the whole night .\n","Input: 그 사람이 좋아하는 것들을 알아보세요.\n","Output: Look at the things that he likes .\n","Input: 간단하게 팔찌나 양말, 모자, 신발 등으로 시작해보세요.\n","Output: Lift it into a simple bracket ,  and shoes and shoes .\n","Input: 오늘 처리할 일 너무 많아\n","Output: There are so many things to deal today .\n","Input: 많이 놀랐겠어요.\n","Output: I will be surprised by a lot .\n","Input: 낮술 조금만 하세요.\n","Output: Please lower the lower than a day .\n","Input: 면허 없는데 따야겠지\n","Output: I don't have a license ,  but I guess I'm hurt .\n","Input: 재활용도 안되는 사람에 대한 기억으로 괴로워 말아요.\n","Output: Don't be suffering from the memory of the person who is not recycling .\n","Input: 다음에는 우산에 이름이랑 연락처를 적어보세요.\n","Output: Write your name and contact number next time .\n","Input: 한가지만 보면 몰라요.\n","Output: I don't know if I look at it .\n","Input: 너무 무리하면 지쳐요.\n","Output: If it is too difficult ,  I get hurt .\n","Input: 이별이 온 후\n","Output: After the farewell ,  it is over .\n","Input: 마음이 복잡하겠어요.\n","Output: I have a complex mind .\n","Input: 힘들 때네요.\n","Output: It is hard time .\n","Input: 친구들과 잘 어울려보세요.\n","Output: Try to go well with your friends .\n","Input: 배송 중이래\n","Output: I am sending the delivery charge .\n","Input: 멍 때리기\n","Output: I am so sleepy .\n","Input: 여기까지가 한계야\n","Output: This is the limit to here .\n","Input: 누구나 몰려가는 줄에 설 필요는 없어요.\n","Output: Nobody has no need to go down the line .\n","Input: 아이스크림 먹어보세요\n","Output: Try ice cream .\n","Input: 짝사랑 시작하고 감정 기복이 심해.\n","Output: The emotional heart starts and emotional smell is so boring .\n","Input: 2년사귀다가 헤어젔는데\n","Output: I broke up with two years old .\n","Input: 한동안은 힘들지도 몰라요.\n","Output: It might be hard for a long time .\n","Input: 어떻게 하느냐에 따라 다를 거예요.\n","Output: It depends on how you are .\n","Input: 동성을 좋아하는게 비정상이 아닌걸 아는데 고백하는건 망설여져.\n","Output: I don't know that homosexuality is normal ,  but it is a great hesitation .\n","Input: 이젠 잊기로 해\n","Output: Now let's forget about it .\n","Input: 여자예요? 남자예요?\n","Output: Is it a woman who is a woman ?\n","Input: 도대체 무슨 꿈을 꾼 건가요.\n","Output: I will change my dream .\n","Input: 중요한 건 노력하는 과정이에요.\n","Output: The important thing is the process to make an effort .\n","Input: 사랑을 시작하게\n","Output: I will start love .\n","Input: 운동하면 뭐 하나\n","Output: What is doing after exercising .\n","Input: 많이 만나보세요.\n","Output: Meet a lot .\n","Input: 좋아하나봐요.\n","Output: I guess I like it .\n","Input: 엇갈리는 느낌 싫다\n","Output: I don't like the feeling of being upset .\n","Input: 내일 짝녀랑 영화보러갑니다.\n","Output: I go to see a movie with my daughter tomorrow .\n","Input: 태연하게 시작해보세요.\n","Output: Start it a lot .\n","Input: 무엇이든 말해보세요.\n","Output: Please tell me anything about anything .\n","Input: 카페 가서 차 마셔도 돼요.\n","Output: You can go to the café and drink tea .\n","Input: 학교 폭력은 범죄에요.\n","Output: The school violence is a crime .\n","Input: 술 마시다가 더 무너져요.\n","Output: I drink and get out of my stomach .\n","Input: 이 말 기억하세요.\n","Output: Remember this word .\n","Input: 그러면 얼른 쟁취하세요.\n","Output: Then be careful about it .\n","Input: 이 여자 유부녀인가\n","Output: This woman is a kid .\n","Input: 썸 중에 고백 언제가 적절해?\n","Output: When is the high hour of the sour ?\n","Input: 자야하는데~~\n","Output: I have to go to bed for something .\n","Input: 하나씩 하세요.\n","Output: Please give it one one .\n","Input: 챙겨 드세요.\n","Output: Please take care of yourself .\n","Input: 기억도 안 나는 사소한 일로 싸워요.\n","Output: I don't remember it so much about small things .\n","Input: 봄은 항상 돌아오죠.\n","Output: Spring is always back .\n","Input: 멋진 삶을 살고 싶어\n","Output: I want to live a wonderful life .\n","Input: 돈 모으는 재미\n","Output: It is fun for money .\n","Input: 쉬운 일이 아니지만 함께라면 가능할 거예요.\n","Output: It will be possible if it is not easy but if it is possible .\n","Input: 짧으면 짧을 수록 좋죠.\n","Output: The shorter the short time .\n","Input: 얼마 되지 않았네요.\n","Output: It's not been a long time .\n","Input: 인연이 아니었나봅니다.\n","Output: I guess it was not a relationship .\n","Input: 좋아하는 걸로 착각하고 있었을 수도 있어요.\n","Output: It might have been a mistake since I liked it .\n","Input: 원피스 입는 게 낫겠지\n","Output: It must be better to wear a dress .\n","Input: 기회가 다시 올 거예요.\n","Output: I will come back .\n","Input: 사랑하니까 예뻐보이는 걸 수도 있어요.\n","Output: I can see you look pretty .\n","Input: 별똥별 떨어지는 날\n","Output: It is the day of the stars .\n","Input: 차였지만 잊지못하고 있는 한 남자입니다.\n","Output: It was a car but a guy who has not forgotten but an unforgettable man who is forgetting it .\n","Input: 썸 타는 사이에 얼마나 간섭 가능?\n","Output: How long can you take a lot of time to get on a trip ?\n","Input: 노력하고 있어요.\n","Output: I'm trying hard .\n","Input: 더 깊은 공부할 수 있을 거예요.\n","Output: I will be able to study more deeply than myself .\n","Input: 사귀기 전에 감정을 갖고 서로 알아가는 단계라면 썸일 거예요.\n","Output: I guess it will be a step if we get each other before making a relationship .\n","Input: 고민이 많은데 표현을 못하겠어\n","Output: I can't express my worries .\n","Input: 추억이 있나봐요.\n","Output: Let's have a memory .\n","Input: 오늘 마지막 연락했습니다\n","Output: I contacted you today .\n","Input: 남자들은 좋아하는 여자한테 이럴 수 있어?\n","Output: Can men do this kind of thing to women like ?\n","Input: 그런 사람 얼른 잊으세요.\n","Output: Please forget that person quickly .\n","Input: 그분에게 심경 변화가 있었나봅니다.\n","Output: I guess there was a change in his mind .\n","Input: 인생은 반복의 연속이지요.\n","Output: Life is a series of repeated in the life .\n","Input: 날씨가 많이 풀렸죠.\n","Output: The weather is too cool .\n","Input: 남친이 나보다 눈물이 더 많아\n","Output: There are more friends than others .\n","Input: 좀 먹어도 괜찮아요.\n","Output: It's fine to eat .\n","Input: 바쁘거나 썸이 끝났거나겠죠.\n","Output: It must be over ,  or a hard time .\n","Input: 존재 자체로 큰 힘이 되어주고 있나봅니다.\n","Output: I think it is a big power to be a human beings .\n","Input: 사랑이 모두 정답이 될수는 없어요.\n","Output: We cannot all answer .\n","Input: 그녀에게도 후폭풍이 올까??\n","Output: Is the storm with a climate ?\n","Input: 도전하기 싫다\n","Output: I don't want to challenge myself .\n","Input: 우울합니다\n","Output: I feel depressed about my depression .\n","Input: 같이 놀아요.\n","Output: Let's hang out together .\n","Input: 더 좋은 사람 만날 거예요.\n","Output: I'm going to meet a better person .\n","Input: 날이 많이 추운데.\n","Output: It's a cold day .\n","Input: 같이 놀러갈 친구가 없어\n","Output: I don't have a friend to hang out .\n","Input: 앞머리만이라도 감으세요.\n","Output: Pull your hair in front of you .\n","Input: 후회하지 않았으면 좋겠어요.\n","Output: I hope you don't regret it .\n","Input: 헤어진지 4일\n","Output: I have been careful about my presentation .\n","Input: 마음이 많이 아프겠어요.\n","Output: I feel so sick that I feel so much hurt .\n","Input: 저도 궁금해요.\n","Output: I wonder about it .\n","Input: 남과 비교하지 마세요.\n","Output: Don't compare it with others .\n","Input: 언제쯤 무뎌질까\n","Output: I will get rid of my lips .\n","Input: 그 애의 눈에도 당신이 띄길 바랄게요.\n","Output: I hope you are coming into your eyes .\n","Input: 여유는 마음 가짐에 있어요.\n","Output: It is in my mind .\n","Input: 괜한 의미부여는 하지 마세요.\n","Output: Don't give a meaning of it .\n","Input: 영화관 알바 하고 싶다\n","Output: I want to go to a part-time job at the cinema .\n","Input: 심심하다고\n","Output: I'm bored with my mind .\n","Input: 잘하는 건 칭찬해주고 본받을 점은 본받으면서 그대로 사랑해주세요.\n","Output: Please love to be a compliment and receive it as soon as you receive it .\n","Input: 버려줘서 고마워.\n","Output: Thank you for throwing away .\n","Input: 다양하게 먹자고 해보세요.\n","Output: Let's eat and eat .\n","Input: 한강에서 소주한잔.\n","Output: I have a drink at Han River .\n","Input: 대청소를 해보세요!\n","Output: Try cleaning up your country !\n","Input: 숙면하겠네요.\n","Output: I guess I will be homeless .\n","Input: 잠이 최고의 보약이에요. 노력해보세요.\n","Output: This is the best medicine and try hard .\n","Input: 귀엽게 봐주세요.\n","Output: Please take a look at it .\n","Input: 힘들지 않았다면 거짓말일 거예요.\n","Output: If it wasn't difficult ,  I will lie .\n","Input: 질긴 인연 드디어 끝인 것 같네\n","Output: I think it's finally the end of a relationship .\n","Input: 물 좋은데 어디야?\n","Output: I like water but where are you doing ?\n","Input: 청첩장 만들어야지\n","Output: It's a invitation made of Cheong .\n","Input: 미래를 더 준비하고 있나봐요.\n","Output: Let's get ready to get together more and get better .\n","Input: 제발 좀 정신차리세요.\n","Output: Hold your feet on .\n","Input: 그냥 잊어버리세요.\n","Output: Just forget it .\n","Input: 내가 좋아하는 사람이 행복했으면 좋겠다\n","Output: I hope that I like is happy .\n","Input: 후폭풍은 누구에게나 올 거예요.\n","Output: The cliffs will come from .\n","Input: 말수 적은 남자인데 썸타도 괜찮을까?\n","Output: I can't speak but will it be fine even though I am a guy who is not working ?\n","Input: 데려다주려나봐요.\n","Output: Let's take a shower .\n","Input: 심경의 변화가 있었을지도 모르겠네요.\n","Output: I don't know if there was any change in the field .\n","Input: 많이 지쳤을 거예요.\n","Output: I'm going to get tired a lot .\n","Input: 정말 그래요. 하나같이 공감되곤 하죠.\n","Output: Oh ,  let's sympathize together .\n","Input: 미련만 남을 거예요.\n","Output: I'll only have an unusual life .\n","Input: 책 좀 읽어야지\n","Output: I should read a book a lot .\n","Input: 계속 속이 진짜 안 좋아\n","Output: I really don't like it anymore .\n","Input: 바쁘거나 거절의 의미일 수도 있겠어요.\n","Output: It might be a meaning of a busy or decline .\n","Input: 모 아니면 도예요.\n","Output: It's a trim or a third .\n","Input: 그녀의 관심사에 호감을 드러내세요.\n","Output: Please show her interest in her interests .\n","Input: 결혼이야기를 꺼내고 싶은데 어느 분위기에 꺼내는게 좋을까?\n","Output: I want to get married but which atmosphere would be better to get out of any atmosphere ?\n","Input: 안경 빼니까 예뻐보여\n","Output: I look pretty because I lost my glasses .\n","Input: 소심남 좋아하는 여자도 있나요?\n","Output: Is there a woman who likes So-gi ?\n","Input: 있을 수 있지요.\n","Output: You can do it .\n","Input: 필요한 게 뭔지 살펴보세요.\n","Output: Please look at what you need .\n","Input: 코 감기일 수도 있어요.\n","Output: You can have a cold .\n","Input: 나랑 같이 놀아요.\n","Output: Let's hang out together .\n","Input: 따뜻한 밥 먹고 힘내봐요.\n","Output: Let's have a hard time and cheer up .\n","Input: 저는 위기 조차 없네요.\n","Output: I don't even have any crisis .\n","Input: 무언가의 탄생을 뜻하기도 해요.\n","Output: It means a happy life .\n","Input: 더 일찍 일어나세요.\n","Output: You get up earlier early .\n","Input: 좋은 여행 되길 바랍니다.\n","Output: I hope you have a nice trip .\n","Input: 슬픈 이야기네요.\n","Output: I am sad about it .\n","Input: 나 폰 중독인 거 같애\n","Output: I think I'm a child .\n","Input: 나 자신에 집중하세요. 언제나 1순위에 자신을 두세요.\n","Output: I will concentrate on myself ,  always on top priority .\n","Input: 우산 같은 사람이네요.\n","Output: I am the same person .\n","Input: 불금이네\n","Output: It's a non-smoking one .\n","Input: 같이 내는 게 좋죠.\n","Output: It's good to be together .\n","Input: 전여친이 나보다 나은 사람이라는 생각이 자꾸 들어\n","Output: I think that all of my life is better than anyone else .\n","Input: 바람 쐬고 와서 다시 들으세요.\n","Output: Come over and listen to it again .\n","Input: 근처 산에 가보세요.\n","Output: Go to the mountain near you .\n","Input: 달리세요!\n","Output:  !\n","Input: 잘 할 수 있을지 걱정 돼\n","Output: I am worried if I can do well .\n","Input: 조심히 오세요.\n","Output: Be careful with you .\n","Input: 잘 이겨내고 있네요.\n","Output: I'm getting into a good job .\n","Input: 궁금할 수 있어요.\n","Output: I can ask something .\n","Input: 안 사귀는 것보다 좋지요.\n","Output: It's better than a relationship .\n","Input: 작은것에 감사하는 마음을 가져보세요.\n","Output: Please take your gratitude away .\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"D5ppQMM2jfd9"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1o6q8jbyc8hf2a4p65V6mQ2Vy6R705dmg","timestamp":1670765951792}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"16e5f02754ab0f79f0abaa7cdeb71a09b30b0cb9d46aa2a551c0ac5a1ab0d914"}}},"nbformat":4,"nbformat_minor":0}